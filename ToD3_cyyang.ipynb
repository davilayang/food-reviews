{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data for D3 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147304, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'D:\\DATA\\OurFoods'\n",
    "df = pd.read_csv(os.path.join(data_path, 'merged_amz-off_3.csv.gz'),\\\n",
    "                 dtype={'customer_id': 'object', 'product_parent': 'object', \\\n",
    "                        'star_rating': pd.Int64Dtype(), 'helpful_votes': pd.Int64Dtype(), \n",
    "                        'total_votes': pd.Int64Dtype(), \\\n",
    "                        'code': 'object'},\n",
    "                 compression='gzip')\n",
    "# convert reivew_date to datetime object\n",
    "df.review_date = pd.to_datetime(df.review_date)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import types\n",
    "\n",
    "from dotenv import load_dotenv # env variables\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLALCHEMY_DATABASE_URI = os.getenv('DATABASE_URL')\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Column Type inherited from DataFrame `info`\n",
    "+ object => text\n",
    "+ Int64 => bigint\n",
    "+ datetime64[ns] => timestamp without time zone \n",
    "+ float64 => double precision   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(name=\"sample_table\", con=engine, if_exists='replace',\\\n",
    "          schema='public', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x20eb27cfe10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add review_id as primary key\n",
    "engine.execute(\"ALTER TABLE sample_table ADD PRIMARY KEY (review_id);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ create a connection, query then close it:\n",
    "```python\n",
    "connection = engine.connect()  \n",
    "result = connection.execute(\"select * from skilltree\")\n",
    "for row in result:\n",
    "    print(row)\n",
    "connection.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "+ engine create and close the connectio itself:\n",
    "```python\n",
    "result = engine.execute(\"select * from skilltree\")\n",
    "for row in result:\n",
    "    print(row)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Ridgeline Plot\n",
    "+ Input: \n",
    "  + Merged Food Reviews dataset\n",
    "  + A range of time, including \"start date\" and \"end date\"\n",
    "+ Ouput:\n",
    "  + Data of TOP10 Counts within the time range\n",
    "  + Including these attributes:\n",
    "    + For each category, data of one day is computed\n",
    "      + **p: probability of reviews in a given date**\n",
    "        + i.e. (count of day reviews) / (count of whole time reivews)\n",
    "      + **p peak: normalize p with the maximum p (of whole range)**\n",
    "        + i.e. (p of a date) / (max p of whole time range)\n",
    "      + **p smooth: smooth p with adjacent p data**\n",
    "        + i.e. (p of a date) / (sum of p data adjacent to it, including previous, current, next)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147304, 23)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of Data\n",
    "+ Keep only Valid Data\n",
    "+ Slice by Date Range\n",
    "+ Slice by TOP 10 Threshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep only valid date, with [category, review_date, id]\n",
    "sub = df[(df.energy_100g.notna()) & (df.energy_100g < 3000) & \n",
    "         (df.salt_100g < 100) & (df.review_date.notna()) & \n",
    "         (df.main_category_en.notna()) & (df.main_category_en.str.contains('^[A-Z].*'))]\\\n",
    "        .loc[:, ['main_category_en', 'review_date', 'review_id']]\\\n",
    "        .rename(mapper={'main_category_en': 'category', 'review_id': 'id'}, axis=1)\\\n",
    "        .reset_index(drop=True)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# slice by date range\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2014-12-31'\n",
    "\n",
    "sub = sub[(sub.review_date >= start_date) & (sub.review_date <= end_date)]\n",
    "# sub = sub[(sub.review_date > start_date) & (sub.review_date < end_date)]\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Pattern Matching, w/ SIMILAR TO\n",
    "  + https://www.postgresql.org/docs/9.0/functions-matching.html\n",
    "+ give `%%` to use it as `%` because `%` in python is use as string formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2014-01-01'\n",
    "end_date = '2014-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \\\n",
    "\"\"\"\n",
    "SELECT \n",
    "    main_category_en AS category, \n",
    "    review_date, \n",
    "    review_id AS id\n",
    "FROM \n",
    "    sample_table\n",
    "WHERE \n",
    "    energy_100g IS NOT NULL\n",
    "    AND review_date IS NOT NULL\n",
    "    AND main_category_en IS NOT NULL\n",
    "    AND energy_100g < 3000\n",
    "    AND salt_100g < 100\n",
    "    AND main_category_en SIMILAR TO '[A-Z]_*'\n",
    "    AND review_date BETWEEN '{0}' AND '{1}'\n",
    "ORDER BY\n",
    "    review_date\n",
    "\"\"\".format(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 10 threshold\n",
    "threshold = sub.groupby('category')[['id']].count()\\\n",
    "    .sort_values('id', ascending=False)\\\n",
    "    .iloc[9, 0] # get 10th category count\n",
    "threshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query = \\\n",
    "\"\"\"\n",
    "SELECT \n",
    "    main_category_en AS category,\n",
    "    COUNT(review_id) AS id\n",
    "FROM \n",
    "    sample_table\n",
    "WHERE \n",
    "    energy_100g IS NOT NULL\n",
    "    AND review_date IS NOT NULL\n",
    "    AND main_category_en IS NOT NULL\n",
    "    AND energy_100g < 3000\n",
    "    AND salt_100g < 100\n",
    "    AND main_category_en SIMILAR TO '[A-Z]_*'\n",
    "    AND review_date BETWEEN '{0}' AND '{1}'\n",
    "GROUP BY\n",
    "    main_category_en\n",
    "ORDER BY \n",
    "    id DESC\n",
    "LIMIT 10\n",
    "\"\"\".format(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16048, 4)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sice by TOP10 threshold\n",
    "top10 = sub.assign(counts=lambda d: d.groupby('category')[['id']].transform('count'))\\\n",
    "        .query('counts >= {}'.format(threshold))\\\n",
    "        .reset_index(drop=True)\n",
    "top10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Range index\n",
    "+ Not Every Category has data for every date in the range\n",
    "+ Supplement with 0 value \n",
    "+ Use Date Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3650"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_idx = []\n",
    "for category in top10.category.unique():\n",
    "    for date in pd.date_range(start_date, end_date, freq='D'):\n",
    "        date_idx.append((category, date))\n",
    "len(date_idx) # (number of category) * (number of days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Plot Values\n",
    "+ P\n",
    "+ P Peak\n",
    "+ P Smooth (use more days for smoothing?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 3)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p attribute\n",
    "data = top10.groupby(['category', 'review_date'])[['id']].count()\\\n",
    "    .reindex(date_idx, fill_value=0)\\\n",
    "    .reset_index()\\\n",
    "    .assign(byCategorySum=lambda d: d.groupby('category')[['id']].transform('sum'))\\\n",
    "    .assign(p=lambda d: d.id / d.byCategorySum)\\\n",
    "    .drop(['id', 'byCategorySum'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 4)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p peak attribute\n",
    "data = data.assign(byCategoryMaxP=lambda d: d.groupby('category')[['p']].transform(max))\\\n",
    "    .assign(p_peak=lambda d: d.p / d.byCategoryMaxP)\\\n",
    "    .drop(['byCategoryMaxP'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 5)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p smooth attribute\n",
    "data = data.assign(p_lag1=lambda d: d.groupby('category')[['p_peak']].shift(-1))\\\n",
    "    .assign(p_lead1=lambda d: d.groupby('category')[['p_peak']].shift(1))\\\n",
    "    .assign(p_smooth=lambda d: (d.p_lag1 + d.p_peak + d.p_lead1) / 3)\\\n",
    "    .drop(['p_lag1', 'p_lead1'], axis=1)\\\n",
    "    .fillna(method='ffill', axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 6)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p smooth attribute, w/ 7 days smoothing\n",
    "data = data\\\n",
    "    .assign(p_lag1=lambda d: d.groupby('category')[['p_peak']].shift(-1))\\\n",
    "    .assign(p_lag2=lambda d: d.groupby('category')[['p_peak']].shift(-2))\\\n",
    "    .assign(p_lag3=lambda d: d.groupby('category')[['p_peak']].shift(-3))\\\n",
    "    .assign(p_lead1=lambda d: d.groupby('category')[['p_peak']].shift(1))\\\n",
    "    .assign(p_lead2=lambda d: d.groupby('category')[['p_peak']].shift(2))\\\n",
    "    .assign(p_lead3=lambda d: d.groupby('category')[['p_peak']].shift(3))\\\n",
    "    .assign(p_smooth7=lambda d: (d.p_lag1 + d.p_lag2 + d.p_lag3 + \n",
    "                                 d.p_lead1 + d.p_lead2 + d.p_lead3 +\n",
    "                                 d.p_peak) / 7)\\\n",
    "    .drop(['p_lag1', 'p_lag2', 'p_lag3', 'p_lead1', 'p_lead2', 'p_lead3'], axis=1)\\\n",
    "    .fillna(method='ffill', axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# export to csv\n",
    "data.to_csv('reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# export to json, as records\n",
    "# [{category: ..., review_date: ..., p: ..., p_peak: ..., p_smooth: ...}, {}, {}, ...]\n",
    "data.iloc[:3, :].to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Statcked Area Plot\n",
    "+ Input: \n",
    "  + Merged Food Reviews dataset\n",
    "  + A range of time, including \"start date\" and \"end date\"\n",
    "+ Ouput:\n",
    "  + Data of TOP10 Counts w/ star rating within the time range\n",
    "  + Including these attributes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep only valid date, with [category, review_date, id]\n",
    "sub = df[(df.energy_100g.notna()) & (df.energy_100g < 3000) & \n",
    "         (df.salt_100g < 100) & (df.review_date.notna()) & \n",
    "         (df.main_category_en.notna()) & (df.main_category_en.str.contains('^[A-Z].*'))]\\\n",
    "        .loc[:, ['main_category_en', 'review_date', 'review_id', 'star_rating']]\\\n",
    "        .rename(mapper={'main_category_en': 'category', 'review_id': 'id'}, axis=1)\\\n",
    "        .reset_index(drop=True)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# slice by date range\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2014-12-31'\n",
    "\n",
    "sub = sub[(sub.review_date > start_date) & (sub.review_date < end_date)]\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2014-01-01'\n",
    "end_date = '2014-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \\\n",
    "\"\"\"\n",
    "SELECT \n",
    "    main_category_en AS category, \n",
    "    review_date, \n",
    "    review_id AS id,\n",
    "    star_rating\n",
    "FROM \n",
    "    sample_table\n",
    "WHERE \n",
    "    energy_100g IS NOT NULL\n",
    "    AND review_date IS NOT NULL\n",
    "    AND main_category_en IS NOT NULL\n",
    "    AND energy_100g < 3000\n",
    "    AND salt_100g < 100\n",
    "    AND main_category_en SIMILAR TO '[A-Z]_*'\n",
    "    AND review_date BETWEEN '{0}' AND '{1}'\n",
    "ORDER BY\n",
    "    review_date\n",
    "\"\"\".format(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17513, 4)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_sql(query, con=engine)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 10 threshold\n",
    "threshold = sub.groupby('category')[['id']].count()\\\n",
    "    .sort_values('id', ascending=False)\\\n",
    "    .iloc[9, 0] # get 10th category count\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16048, 5)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sice by TOP10 threshold and add attribute of each month (date)\n",
    "top10 = sub.assign(counts=lambda d: d.groupby('category')[['id']].transform('count'))\\\n",
    "        .query('counts >= {}'.format(threshold))\\\n",
    "        .assign(year=lambda d: d.review_date.dt.year, month=lambda d: d.review_date.dt.month)\\\n",
    "        .assign(date=lambda d: pd.to_datetime({'year': d.year, 'month': d.month, 'day': 1}) + MonthEnd(0))\\\n",
    "        .drop(['review_date', 'year', 'month'], axis=1)\\\n",
    "        .reset_index(drop=True)\n",
    "top10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>counts</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plant-based foods and beverages</td>\n",
       "      <td>R2R89SB5NTN2S4</td>\n",
       "      <td>5</td>\n",
       "      <td>4330</td>\n",
       "      <td>2014-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plant-based foods and beverages</td>\n",
       "      <td>R3ITMBCU6TYFNK</td>\n",
       "      <td>1</td>\n",
       "      <td>4330</td>\n",
       "      <td>2014-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beverages</td>\n",
       "      <td>RJ73WTW1DYKB6</td>\n",
       "      <td>5</td>\n",
       "      <td>4313</td>\n",
       "      <td>2014-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>R1XZA5DARTY6UC</td>\n",
       "      <td>1</td>\n",
       "      <td>3487</td>\n",
       "      <td>2014-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>RN1JCBRZTJQBH</td>\n",
       "      <td>1</td>\n",
       "      <td>3487</td>\n",
       "      <td>2014-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category              id  star_rating  counts  \\\n",
       "0  Plant-based foods and beverages  R2R89SB5NTN2S4            5    4330   \n",
       "1  Plant-based foods and beverages  R3ITMBCU6TYFNK            1    4330   \n",
       "2                        Beverages   RJ73WTW1DYKB6            5    4313   \n",
       "3                           Snacks  R1XZA5DARTY6UC            1    3487   \n",
       "4                           Snacks   RN1JCBRZTJQBH            1    3487   \n",
       "\n",
       "        date  \n",
       "0 2014-01-31  \n",
       "1 2014-01-31  \n",
       "2 2014-01-31  \n",
       "3 2014-01-31  \n",
       "4 2014-01-31  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Range index\n",
    "+ Not Every Product of a Category has data for the given range\n",
    "+ Use date index to fill the gaps, and fill with 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 3 layer multi-index to one-layer idnex + two-layers column\n",
    "import numpy as np\n",
    "index = pd.MultiIndex.from_tuples([('one', 'a', 'x'), ('one', 'a', 'y'), ('one', 'a', 'z'), \n",
    "                                   ('one', 'b', 'x'), ('one', 'b', 'y'), ('one', 'b', 'z'),\n",
    "                                   ('two', 'a', 'x'), ('two', 'a', 'y'), ('two', 'a', 'z'), \n",
    "                                   ('two', 'b', 'x'), ('two', 'b', 'y') ,('two', 'b', 'z')])\n",
    "s = pd.Series(np.arange(1.0, 13.0), index=index)\n",
    "s.unstack(level=[0, 1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(pd.Timestamp('2014-01-01')+MonthEnd(1)) # return end of month\n",
    "print(pd.Timestamp('2014-01-31')+MonthEnd(1)) # return next month end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(pd.Timestamp('2014-01-01')+MonthEnd(0)) # return end of month\n",
    "print(pd.Timestamp('2014-01-31')+MonthEnd(0)) # return next month end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get end of month with MonthEnd(0)\n",
    "top10 = top10.assign(year=lambda d: d.review_date.dt.year, month=lambda d: d.review_date.dt.month)\\\n",
    "    .assign(date=lambda d: pd.to_datetime({'year': d.year, 'month': d.month, 'day': 1}) + MonthEnd(0))\\\n",
    "    .drop(['review_date', 'year', 'month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_idx = []\n",
    "for category in top10.category.unique():  # category\n",
    "    for rating in range(1, 6): # rating from 1 to 5\n",
    "        for date in pd.date_range(start_date, end_date, freq='M'):  # months in given time\n",
    "            date_idx.append((category, rating, date))\n",
    "len(date_idx) # (number of category) * (number of product in a category) * (number of days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Plant-based foods and beverages</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Beverages</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Dairies</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Sweeteners</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>247</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-28</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>215</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>183</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>268</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-30</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>181</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-31</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>183</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-30</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>180</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-31</th>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>296</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "      <td>301</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-31</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>313</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>348</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-30</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>313</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-31</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>289</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>48</td>\n",
       "      <td>292</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-30</th>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>290</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>319</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>392</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>391</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "category    Plant-based foods and beverages                  Beverages      \\\n",
       "star_rating                               1   2   3   4    5         1   2   \n",
       "date                                                                         \n",
       "2014-01-31                               18  13  19  40  247        23   9   \n",
       "2014-02-28                               15  10  17  29  215        14   9   \n",
       "2014-03-31                               18  10  25  55  268        15  16   \n",
       "2014-04-30                               24  10  13  35  181        23  11   \n",
       "2014-05-31                               10   7  14  32  183        23   7   \n",
       "2014-06-30                               18   4  15  28  180        24  16   \n",
       "2014-07-31                               26  16  33  48  296        20  11   \n",
       "2014-08-31                               21   9  18  45  313        25  12   \n",
       "2014-09-30                               21   7  17  53  313        19  15   \n",
       "2014-10-31                               21  21  26  39  289        30  15   \n",
       "2014-11-30                               24  11  29  47  290        32  27   \n",
       "2014-12-31                               34  13  23  45  392        25  19   \n",
       "\n",
       "category                  ... Dairies              Sweeteners               \n",
       "star_rating   3   4    5  ...       1  2  3  4   5          1  2  3  4   5  \n",
       "date                      ...                                               \n",
       "2014-01-31   16  25  176  ...       2  1  0  5  14          1  1  3  2  13  \n",
       "2014-02-28   13  24  183  ...       2  0  1  3  11          1  5  6  7  20  \n",
       "2014-03-31   23  35  158  ...       0  1  1  2  16          3  2  3  6  33  \n",
       "2014-04-30   21  28  210  ...       2  1  0  0   7          1  1  0  3  16  \n",
       "2014-05-31   22  34  173  ...       0  0  2  2  14          0  2  6  2   9  \n",
       "2014-06-30   19  48  190  ...       3  0  2  1  11          1  0  3  2  14  \n",
       "2014-07-31   26  59  301  ...       1  1  2  2  17          1  1  0  2  18  \n",
       "2014-08-31   24  70  348  ...       4  0  1  0   9          0  1  1  2  28  \n",
       "2014-09-30   23  54  290  ...       0  0  1  3  13          5  3  1  3   9  \n",
       "2014-10-31   25  48  292  ...       0  1  2  3  22          0  1  3  2  16  \n",
       "2014-11-30   43  53  319  ...       1  0  1  5  16          4  1  2  4  24  \n",
       "2014-12-31   19  69  391  ...       1  0  1  3  17          0  1  2  8  21  \n",
       "\n",
       "[12 rows x 50 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date of rating count, of a category, by each month\n",
    "data = top10.groupby(['category', 'star_rating', 'date'])[['id']].count()\\\n",
    "    .reindex(date_idx, fill_value=0)\\\n",
    "    .unstack(level=[0, 1])  # unstack to move indices to columns\n",
    "# drop the id column\n",
    "data.columns = data.columns.droplevel(level=0)\n",
    "# remove index name\n",
    "# data.index.name = None\n",
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.to_csv('file.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# JSON cannot have array as key, \n",
    "# w/ multi-index column, this is in correct\n",
    "data.reset_index().to_json(path, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\Dropbox\\!FullStack-DataScientist\\1_FRONT-END\\D3\\D3-FlaskServer\\static\\data\\local.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\\\Dropbox\\\\!FullStack-DataScientist\\x01_FRONT-END\\\\D3\\\\D3-FlaskServer\\\\static\\\\data\\\\local.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-76ee1f8e4dff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'split'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# split into {'columns': ..., 'data': ..., 'index': ...}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index)\u001b[0m\n\u001b[0;32m   2423\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2424\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2425\u001b[1;33m             \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2426\u001b[0m         )\n\u001b[0;32m   2427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\\\Dropbox\\\\!FullStack-DataScientist\\x01_FRONT-END\\\\D3\\\\D3-FlaskServer\\\\static\\\\data\\\\local.json'"
     ]
    }
   ],
   "source": [
    "data.to_json(path, orient='split')\n",
    "# split into {'columns': ..., 'data': ..., 'index': ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sklearn)",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
