{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data for D3 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147304, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'D:\\DATA\\OurFoods'\n",
    "df = pd.read_csv(os.path.join(data_path, 'merged_amz-off_3.csv.gz'),\\\n",
    "                 dtype={'customer_id': 'object', 'product_parent': 'object', \\\n",
    "                        'star_rating': pd.Int64Dtype(), 'helpful_votes': pd.Int64Dtype(), \n",
    "                        'total_votes': pd.Int64Dtype(), \\\n",
    "                        'code': 'object'},\n",
    "                 compression='gzip')\n",
    "# convert reivew_date to datetime object\n",
    "df.review_date = pd.to_datetime(df.review_date)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Ridgeline Plot\n",
    "+ Input: \n",
    "  + Merged Food Reviews dataset\n",
    "  + A range of time, including \"start date\" and \"end date\"\n",
    "+ Ouput:\n",
    "  + Data of TOP10 Counts within the time range\n",
    "  + Including these attributes:\n",
    "    + For each category, data of one day is computed\n",
    "      + **p: probability of reviews in a given date**\n",
    "        + i.e. (count of day reviews) / (count of whole time reivews)\n",
    "      + **p peak: normalize p with the maximum p (of whole range)**\n",
    "        + i.e. (p of a date) / (max p of whole time range)\n",
    "      + **p smooth: smooth p with adjacent p data**\n",
    "        + i.e. (p of a date) / (sum of p data adjacent to it, including previous, current, next)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147304, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of Data\n",
    "+ Keep only Valid Data\n",
    "+ Slice by Date Range\n",
    "+ Slice by TOP 10 Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59563, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only valid date, with [category, review_date, id]\n",
    "sub = df[(df.energy_100g.notna()) & (df.energy_100g < 3000) & \n",
    "         (df.salt_100g < 100) & (df.review_date.notna()) & \n",
    "         (df.main_category_en.notna()) & (df.main_category_en.str.contains('^[A-Z].*'))]\\\n",
    "        .loc[:, ['main_category_en', 'review_date', 'review_id']]\\\n",
    "        .rename(mapper={'main_category_en': 'category', 'review_id': 'id'}, axis=1)\\\n",
    "        .reset_index(drop=True)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice by date range\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2014-12-31'\n",
    "\n",
    "sub = sub[(sub.review_date > start_date) & (sub.review_date < end_date)]\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 10 threshold\n",
    "threshold = sub.groupby('category')[['id']].count()\\\n",
    "    .sort_values('id', ascending=False)\\\n",
    "    .iloc[9, 0] # get 10th category count\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15939, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sice by TOP10 threshold\n",
    "top10 = sub.assign(counts=lambda d: d.groupby('category')[['id']].transform('count'))\\\n",
    "        .query('counts >= {}'.format(threshold))\\\n",
    "        .reset_index(drop=True)\n",
    "top10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Range index\n",
    "+ Not Every Category has data for every date in the range\n",
    "+ Supplement with 0 value \n",
    "+ Use Date Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3650"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_idx = []\n",
    "for category in top10.category.unique():\n",
    "    for date in pd.date_range(start_date, end_date, freq='D'):\n",
    "        date_idx.append((category, date))\n",
    "len(date_idx) # (number of category) * (number of days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Plot Values\n",
    "+ P\n",
    "+ P Peak\n",
    "+ P Smooth (use more days for smoothing?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p attribute\n",
    "data = top10.groupby(['category', 'review_date'])[['id']].count()\\\n",
    "    .reindex(date_idx, fill_value=0)\\\n",
    "    .reset_index()\\\n",
    "    .assign(byCategorySum=lambda d: d.groupby('category')[['id']].transform('sum'))\\\n",
    "    .assign(p=lambda d: d.id / d.byCategorySum)\\\n",
    "    .drop(['id', 'byCategorySum'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p peak attribute\n",
    "data = data.assign(byCategoryMaxP=lambda d: d.groupby('category')[['p']].transform(max))\\\n",
    "    .assign(p_peak=lambda d: d.p / d.byCategoryMaxP)\\\n",
    "    .drop(['byCategoryMaxP'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p smooth attribute\n",
    "data = data.assign(p_lag1=lambda d: d.groupby('category')[['p_peak']].shift(-1))\\\n",
    "    .assign(p_lead1=lambda d: d.groupby('category')[['p_peak']].shift(1))\\\n",
    "    .assign(p_smooth=lambda d: (d.p_lag1 + d.p_peak + d.p_lead1) / 3)\\\n",
    "    .drop(['p_lag1', 'p_lead1'], axis=1)\\\n",
    "    .fillna(method='ffill', axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3650, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add p smooth attribute, w/ 7 days smoothing\n",
    "data = data\\\n",
    "    .assign(p_lag1=lambda d: d.groupby('category')[['p_peak']].shift(-1))\\\n",
    "    .assign(p_lag2=lambda d: d.groupby('category')[['p_peak']].shift(-2))\\\n",
    "    .assign(p_lag3=lambda d: d.groupby('category')[['p_peak']].shift(-3))\\\n",
    "    .assign(p_lead1=lambda d: d.groupby('category')[['p_peak']].shift(1))\\\n",
    "    .assign(p_lead2=lambda d: d.groupby('category')[['p_peak']].shift(2))\\\n",
    "    .assign(p_lead3=lambda d: d.groupby('category')[['p_peak']].shift(3))\\\n",
    "    .assign(p_smooth7=lambda d: (d.p_lag1 + d.p_lag2 + d.p_lag3 + \n",
    "                                 d.p_lead1 + d.p_lead2 + d.p_lead3 +\n",
    "                                 d.p_peak) / 7)\\\n",
    "    .drop(['p_lag1', 'p_lag2', 'p_lag3', 'p_lead1', 'p_lead2', 'p_lead3'], axis=1)\\\n",
    "    .fillna(method='ffill', axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "data.to_csv('reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"category\":\"Plant-based foods and beverages\",\"review_date\":1388534400000,\"p\":0.0,\"p_peak\":0.0,\"p_smooth\":0.0,\"p_smooth7\":0.0},{\"category\":\"Plant-based foods and beverages\",\"review_date\":1388620800000,\"p\":0.0041928721,\"p_peak\":0.5294117647,\"p_smooth\":0.3333333333,\"p_smooth7\":0.3333333333},{\"category\":\"Plant-based foods and beverages\",\"review_date\":1388707200000,\"p\":0.0037269974,\"p_peak\":0.4705882353,\"p_smooth\":0.4803921569,\"p_smooth7\":0.4803921569}]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export to json, as records\n",
    "# [{category: ..., review_date: ..., p: ..., p_peak: ..., p_smooth: ...}, {}, {}, ...]\n",
    "data.iloc[:3, :].to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sklearn)",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
