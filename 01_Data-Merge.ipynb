{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Datasets: AMZ and OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# use english stop words list\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# disable SettingWithCopyWarning \n",
    "pd.options.mode.chained_assignment = None # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Food Facts dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949695, 175)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set dtype of code to keep values starting with 0, set dtype of others to avoid DtypeWarning\n",
    "data_path = 'D:\\DATA\\practice-dataset\\zipped'\n",
    "off = pd.read_csv(os.path.join(data_path, 'en.openfoodfacts.org.products.csv.zip'), \\\n",
    "                  dtype={'code': 'object', \n",
    "                         'emb_codes': 'object', 'emb_codes_tags': 'object',\n",
    "                         'first_packaging_code_geo': 'object',\n",
    "                         'cities_tags': 'object', 'additives': 'object',\n",
    "                         'ingredients_from_palm_oil_tags': 'object'}, \\\n",
    "                  compression='zip', sep='\\t')\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle OFF: unnecessary attributes\n",
    "+ Remove non-needed attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop attributes not related not related to reviews analyses\n",
    "dropped_cols = ['creator', 'created_t', 'created_datetime', \\\n",
    "                 'last_modified_t', 'last_modified_datetime', \\\n",
    "                 'generic_name', 'packaging', 'packaging_tags', \\\n",
    "                 'origins', 'origins_tags', \\\n",
    "                 'manufacturing_places', 'manufacturing_places_tags', \\\n",
    "                 'labels', 'emb_codes', 'emb_codes_tags', \\\n",
    "                 'first_packaging_code_geo', 'cities', 'cities_tags', \\\n",
    "                 'purchase_places', 'stores', 'countries', \\\n",
    "                 'ingredients_text', 'traces']\n",
    "# 'categories',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not used for product review\n",
    "off.drop(dropped_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out url columns (columns names containing 'url')\n",
    "off = off.filter(regex=r'^((?!url).)*$', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows without Product Name\n",
    "off = off[off.product_name.notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872540, 145)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Food Facts samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take product of \"Cheetos\" for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 144)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product of Cheetos\n",
    "cheetos = off[off.product_name.str.match(r'^(Cheetos|CHEETOS|cheetos)\\s.*')]\n",
    "cheetos.drop('categories', axis=1, inplace=True)\n",
    "\n",
    "# cheetos.product_name = cheetos.product_name.str.lower() \n",
    "cheetos.reset_index(drop=True, inplace=True)\n",
    "cheetos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Reviews: Grocery dataset\n",
    "+ https://registry.opendata.aws/amazon-reviews/\n",
    "+ https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
    "+ http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2393378, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'D:\\DATA\\practice-dataset\\gzipped'\n",
    "amz = pd.read_csv(os.path.join(data_path, 'amazon_reviews_us_Grocery_v1_00.tsv.gz'), \\\n",
    "                  dtype={'customer_id': 'object', 'product_parent': 'object', \\\n",
    "                         'star_rating': 'object', \n",
    "                         'helpful_votes': pd.Int64Dtype(), 'total_votes': pd.Int64Dtype()}, \\\n",
    "                  compression='gzip', sep='\\t', \\\n",
    "                  error_bad_lines=False, warn_bad_lines=False)\n",
    "# pd.Int64Dtype() allows NaN\n",
    "amz.drop(['marketplace', 'product_category', 'product_id'], axis=1, inplace=True)\n",
    "# row 1841896 contains date as star_rating\n",
    "amz.drop(1841896, axis=0, inplace=True)\n",
    "amz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Grove Square Cappuccino, Single Serve Cup for Keurig K-Cup Brewers',\n",
       "       'Grove Square Cappuccino Single Serve Cappuccino Cups, Hazelnut, K-Cups for Keurig Brewers, 24 ct',\n",
       "       'Grove Square Cappuccino, Caramel, 24-Count Single Serve Cup for Keurig K-Cups',\n",
       "       'Grove Square Cappuccino Single Serve Cappuccino Cups, Hazelnut, Single serve cups for Keurig Brewers, 24 ct',\n",
       "       'Grove Square Cappuccino, French Vanilla, 24-Count for Keurig K-cup Brewers'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one product_parent, but multiple title; most others only have one title\n",
    "amz[amz.product_parent == '795563511'].product_title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Review sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take product of \"cheetos\" for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheetos\n",
    "che_rev = amz[amz.product_title.str.match(r'^(Cheetos|cheetos|CHEETOS)\\s.*')]\n",
    "# che_rev.product_title = che_rev.product_title.str.lower()\n",
    "che_rev.reset_index(drop=True, inplace=True)\n",
    "che_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cheetos Crunchy - 50/1 oz. bags',\n",
       "       'Cheetos Flavored Snacks, Crunchy Cheese, 1.13 Ounce (Pack of 12)',\n",
       "       'Cheetos Crunchy Cheddar Jalapeno Cheese Flavored Snacks',\n",
       "       'Cheetos Crunchy Cheese Flavored Snacks',\n",
       "       \"Cheetos Flamin' Hot and Doritos Dinamita Chile Limon 8.0 Oz [3 Pk]\",\n",
       "       \"Cheetos Flamin' Hot - 50/1 oz\",\n",
       "       'Cheetos Sweetos Cinnamon Sugar Puffs Flavored Snacks, 7 oz (Set of 2)',\n",
       "       \"Cheetos Cheese Flavored Snacks, Crunchy Flamin' Hot, 2.38 Ounce (Pack of 12)\",\n",
       "       'Cheetos Cheese Flavored Snacks, Jumbo Puffs, 9.5 Ounce (Pack of 4)',\n",
       "       'Cheetos Natural White Cheddar Puffs Cheese Flavored Snacks, 8oz Bags (Pack of 12)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first 10\n",
    "che_rev.product_title.unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle AMZ: multiple product_name in a product_parent \n",
    "Get mapping from `product_parent` code\n",
    "+ why? need a unique identifier for merging, but `product_parent` has some errors\n",
    "  + from each `product_parent`, get one product title as the only title\n",
    "  + i.e. get the highest count title from each `product_parent` code\n",
    "+ key: product_parent\n",
    "+ value: product title/name\n",
    "+ how?\n",
    "  + group by product_parent and product_title, count the occurance of another column\n",
    "    + getting multi-index with product_parent and product_title, with only columnt of count\n",
    "  + `reset_index` on the multi-index dataframe, get regular data frame\n",
    "  + method1:\n",
    "    + sort by count values, from large to small; drop duplicates on product_parent\n",
    "    + get the unique product_parent code for each product_title\n",
    "  + method2:\n",
    "    + get index by \n",
    "      + group by prodcut_parent and transform each row to the group's max value\n",
    "      + compare with group max value, the boolean array is the index\n",
    "    + get the unique pair by boolean slicing on array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275498, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by product_parent and product_title, get count of each title under a code\n",
    "# there could be multiple titles under the same code\n",
    "tmp = amz.loc[:, ['product_title', 'product_parent', 'customer_id']]\\\n",
    "        .groupby(['product_parent', 'product_title']).count().reset_index()\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000634</td>\n",
       "      <td>Wild Caught Icelandic Cod, Frozen Cello Pak5 l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100007845</td>\n",
       "      <td>Pamelas Cookie Fgg&amp;Jmms Bluebry&amp;Fig Ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100011767</td>\n",
       "      <td>Hidden Valley Fat Free Ranch Portion Pack Dres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100013042</td>\n",
       "      <td>Prize Winning La Tourangelle Artisinal Gourmet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100016462</td>\n",
       "      <td>Sharwood's Plain Large Puppodums (8 per pack -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_parent                                      product_title\n",
       "0      100000634  Wild Caught Icelandic Cod, Frozen Cello Pak5 l...\n",
       "1      100007845             Pamelas Cookie Fgg&Jmms Bluebry&Fig Ko\n",
       "2      100011767  Hidden Valley Fat Free Ranch Portion Pack Dres...\n",
       "3      100013042  Prize Winning La Tourangelle Artisinal Gourmet...\n",
       "4      100016462  Sharwood's Plain Large Puppodums (8 per pack -..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1\n",
    "mapping = tmp.sort_values('customer_id', ascending=False).drop_duplicates('product_parent')\n",
    "# mapping.shape\n",
    "mapping = mapping.sort_values('product_parent').drop('customer_id', axis=1).reset_index(drop=True)\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 2, (incorrect, still some duplicated product_parent)\n",
    "```python\n",
    "idx = tmp.groupby('product_parent')['customer_id'].transform(max) == tmp['customer_id']\n",
    "mapping = tmp[idx]\n",
    "mapping.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export the mapping\n",
    "```python\n",
    "data_path = 'D:\\DATA\\OurFoods'\n",
    "mapping.to_csv(os.path.join(data_path, 'mapping.csv'), index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Product Name/Title\n",
    "+ Regex for processing names/titles\n",
    "  + lowercasing\n",
    "  + remove non-word but not white space, b.c, special symbols when naming\n",
    "  + remove digit and values after it, b.c. values after digits are packaging size\n",
    "  + remove space, i.e. empty string, in list\n",
    "  + remove stopwords, e.g. 'by', 'the'...etc\n",
    "+ **Problem with Regex**\n",
    "  + many product names/titles starting with digit\n",
    "    + causing too many empty tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pname_tokenize(string):\n",
    "    \"\"\"\n",
    "    Given product name/title string, processes and outputs tuple of tokens\n",
    "    \"\"\"\n",
    "    # lower and remove non-word except spaces\n",
    "    r = re.sub(r'[^\\w\\s]', '', string.lower())\n",
    "    # remove digits and any string after it\n",
    "    r = re.sub(r'\\d.*$', '', r)\n",
    "    # remove empty string and stopwords, then return tuple\n",
    "    return tuple(sorted(set(filter(None, r.split(' '))) - set(stopWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78, 145), (496, 13))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheetos['tokens'] = cheetos.product_name.apply(pname_tokenize)\n",
    "che_rev['tokens'] = che_rev.product_title.apply(pname_tokenize)\n",
    "cheetos.shape, che_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000634</td>\n",
       "      <td>Wild Caught Icelandic Cod, Frozen Cello Pak5 l...</td>\n",
       "      <td>(caught, cello, cod, frozen, icelandic, pak, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100007845</td>\n",
       "      <td>Pamelas Cookie Fgg&amp;Jmms Bluebry&amp;Fig Ko</td>\n",
       "      <td>(bluebryfig, cookie, fggjmms, ko, pamelas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100011767</td>\n",
       "      <td>Hidden Valley Fat Free Ranch Portion Pack Dres...</td>\n",
       "      <td>(dressing, fat, free, hidden, pack, portion, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100013042</td>\n",
       "      <td>Prize Winning La Tourangelle Artisinal Gourmet...</td>\n",
       "      <td>(artisinal, gourmet, la, oil, prize, tourangel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100016462</td>\n",
       "      <td>Sharwood's Plain Large Puppodums (8 per pack -...</td>\n",
       "      <td>(large, plain, puppodums, sharwoods)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_parent                                      product_title  \\\n",
       "0      100000634  Wild Caught Icelandic Cod, Frozen Cello Pak5 l...   \n",
       "1      100007845             Pamelas Cookie Fgg&Jmms Bluebry&Fig Ko   \n",
       "2      100011767  Hidden Valley Fat Free Ranch Portion Pack Dres...   \n",
       "3      100013042  Prize Winning La Tourangelle Artisinal Gourmet...   \n",
       "4      100016462  Sharwood's Plain Large Puppodums (8 per pack -...   \n",
       "\n",
       "                                              tokens  \n",
       "0  (caught, cello, cod, frozen, icelandic, pak, w...  \n",
       "1         (bluebryfig, cookie, fggjmms, ko, pamelas)  \n",
       "2  (dressing, fat, free, hidden, pack, portion, r...  \n",
       "3  (artisinal, gourmet, la, oil, prize, tourangel...  \n",
       "4               (large, plain, puppodums, sharwoods)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding tokens to mapping dataframe\n",
    "mapping['tokens'] = mapping.product_title.apply(pname_tokenize)\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Merge \n",
    "+ keep cateogory and main nutrients\n",
    "+ AMZ dataset\n",
    "  + merge with mapping on unique id, to add tokens to amz\n",
    "+ OFF dataset\n",
    "  + tokenize the product name\n",
    "  + use mapping to find unique id for the token\n",
    "+ Merge\n",
    "  + merge both on unique id (product parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare `amz`\n",
    "+ using mapping dataset\n",
    "+ merget `amz` with mapping to get `tokens` attribute\n",
    "+ some `tokens` are empty, drop by empty tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2393378, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge amz with mapping\n",
    "amz = amz.merge(mapping[['product_parent', 'tokens']], how='left', on='product_parent')\n",
    "amz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2344543, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop empty tuples, for now\n",
    "amz = amz[amz.tokens != tuple()]\n",
    "amz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare `off`\n",
    "+ problems:\n",
    "  + same product, having different pacakge size, is on different row\n",
    "  + i.e. same tokens, but having multiple entries\n",
    "+ either select one of the entries, or taking avearage on all entries\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872540, 145)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872540, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only taking categories and main nutrients\n",
    "sub = off.loc[:, ['product_name', 'categories_tags', 'main_category_en', \\\n",
    "                  'energy_100g', 'fat_100g', 'fiber_100g', 'carbohydrates_100g', \\\n",
    "                  'proteins_100g', 'salt_100g', 'sodium_100g', 'sugars_100g']]\n",
    "sub.sort_values(['product_name', 'main_category_en', 'categories_tags'], \\\n",
    "                inplace=True, na_position='last')\n",
    "sub.reset_index(drop=True, inplace=True)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337571"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main category has missing values \n",
    "sub.main_category_en.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate function for each attribute\n",
    "func = {'categories_tags':'last', 'main_category_en':'last', \\\n",
    "        'energy_100g':'mean', 'fat_100g':'mean', 'fiber_100g':'mean', \\\n",
    "        'carbohydrates_100g':'mean', 'proteins_100g':'mean', \\\n",
    "        'salt_100g':'mean', 'sodium_100g':'mean', 'sugars_100g':'mean'}\n",
    "# for duplicated product_name: \n",
    "# 1. take first value on strings attribute\n",
    "# 2. take mean on numeric attrbutes\n",
    "sub = sub.groupby('product_name', as_index=False).agg(func)\\\n",
    "        .assign(tokens=lambda d: d.product_name.apply(pname_tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for duplicated tokens\n",
    "# use the same aggregate function as before\n",
    "sub = sub[sub.tokens != tuple()].reset_index(drop=True)\\\n",
    "    .groupby('tokens', as_index=False).agg(func)\n",
    "# remove rows without energy data\n",
    "sub = sub[sub.energy_100g.notna()]\n",
    "\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Output both dataset\n",
    "+ need to process the main category, having different language inputs\n",
    "  + remove non-english inputs\n",
    "  + or, replace with english categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147304, 23)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = amz.merge(sub, how='inner', on='tokens')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export as csv file\n",
    "```python\n",
    "data_path = 'D:\\DATA\\OurFoods'\n",
    "df.to_csv(os.path.join(data_path, 'merged_amz-off_3.csv.gz'),\\\n",
    "          compression='gzip', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to database\n",
    "```python\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import types\n",
    "\n",
    "from dotenv import load_dotenv # env variables\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "SQLALCHEMY_DATABASE_URI = os.getenv('DATABASE_URL')\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URI)\n",
    "\n",
    "df.to_sql(name=\"food_reviews\", con=engine, if_exists='replace',\n",
    "               schema='public', index=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sklearn)",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
