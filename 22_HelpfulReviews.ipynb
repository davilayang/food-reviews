{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Reviews Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEAS\n",
    "+ a helpful review is a review that affects other users who read it\n",
    "+ may decourage or encourage buying behaviours\n",
    "+ give data of review, product content, \n",
    "  + how 'helpful' a review is? i.e. helpful votes / total votes\n",
    "  + decourage review or encourage review? and no effect\n",
    "    + no label for this? helpfulness != encourage\n",
    "    + helpfulness + positive sentiment == encourage\n",
    "    + helpfulness + negative sentiment == decourage\n",
    "    + i.e. first get sentiment value, then combine with the helpfulness value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv # env variables\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLALCHEMY_DATABASE_URI = os.getenv('DATABASE_URL')\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Helpfulness of a Review\n",
    "+ Take reviews with votes, Predict if a review is helpful or not\n",
    "+ using threshold .5 as helpful or not\n",
    "1. Clean reviews with `re`\n",
    "2. Tokenize with `sklearn` \n",
    "3. Train model with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "+ Use Word-Embedding? Gensim? spacey?\n",
    "+ Use custom methods to clean strings\n",
    "+ Lemmatizing? Stemming? POS Tags?\n",
    "  + `from nltk.stem import WordNetLemmatizer`\n",
    "  + `from nltk.stem import PorterStemmer`\n",
    "+ Feature Engineering\n",
    "  + Time of review may affect its helpfulness\n",
    "  + Length of headline or body\n",
    "  + Number of break line used in review\n",
    "  + Maybe the first few words are more important?\n",
    "+ Prediction: \n",
    "  + a numeric value between 0 and 1, regression\n",
    "  + use different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44363, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \\\n",
    "\"\"\"\n",
    "SELECT \n",
    "    helpful_votes, total_votes,\n",
    "    review_headline, review_body\n",
    "FROM \n",
    "    food_reviews\n",
    "WHERE \n",
    "    energy_100g IS NOT NULL\n",
    "    AND energy_100g < 3000\n",
    "    AND review_date >= '2010-01-01'\n",
    "    AND verified_purchase LIKE 'Y'\n",
    "    AND total_votes > 0\n",
    "\"\"\"\n",
    "# helpfulness = helpful votes / total votes\n",
    "df = pd.read_sql(sql, con=engine)\\\n",
    "    .assign(helpful=lambda df: df.helpful_votes/df.total_votes > .5)\\\n",
    "    .drop(['helpful_votes', 'total_votes'], axis=1)\n",
    "#     .assign(helpfulness=lambda df: df.helpful_votes/df.total_votes)\\\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prcoessing with individual functions \n",
    "def remove_nonword(string):\n",
    "    # remove line breaker, non-word, except space and period,\n",
    "    return re.sub(r'<br />|[^A-Za-z. ]', '', string.lower())\n",
    "def remove_space(string):\n",
    "    # remove space at setence end\n",
    "    return re.sub(r'\\s$', '', string)\n",
    "def reduce_spaces(string):\n",
    "    # reduce multiple space to single\n",
    "    return re.sub(' +', ' ', string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>five stars</td>\n",
       "      <td>it works well for nagging sensations in the st...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its not all natural and also surprise it got c...</td>\n",
       "      <td>look at the ingredients dear future customers....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>five stars</td>\n",
       "      <td>if you want angostura this is the real thing. ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best old fashion drinks..</td>\n",
       "      <td>great for making a cocktail name old fashion.....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>five stars</td>\n",
       "      <td>excellent product and very fast shipping</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     review_headline  \\\n",
       "0                                         five stars   \n",
       "1  its not all natural and also surprise it got c...   \n",
       "2                                         five stars   \n",
       "3                          best old fashion drinks..   \n",
       "4                                         five stars   \n",
       "\n",
       "                                         review_body  helpful  \n",
       "0  it works well for nagging sensations in the st...     True  \n",
       "1  look at the ingredients dear future customers....    False  \n",
       "2  if you want angostura this is the real thing. ...    False  \n",
       "3  great for making a cocktail name old fashion.....    False  \n",
       "4           excellent product and very fast shipping    False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the processing functions\n",
    "funcs = [remove_nonword, remove_space, reduce_spaces]\n",
    "for func in funcs:\n",
    "    df.review_headline = df.review_headline.apply(func)\n",
    "    df.review_body = df.review_body.apply(func)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "# from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39926, 2), (4437, 2), (39926,), (4437,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['helpful'], axis=1),\n",
    "    df.helpful, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pipe to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to easy workflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion # join features\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # base class\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select text \n",
    "headlines = Pipeline([\n",
    "    ('selector', TextSelector(key='review_headline')),\n",
    "    ('countVec', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True))\n",
    "])\n",
    "bodies = Pipeline([\n",
    "    ('selector', TextSelector(key='review_body')),\n",
    "    ('countVec', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True))\n",
    "])\n",
    "# select have_url fearture # no change in accuracy\n",
    "# bool_url = Pipeline([\n",
    "#     ('selector', NumberSelector(key='have_url'))\n",
    "# ])\n",
    "\n",
    "# union all features together\n",
    "features = FeatureUnion([\n",
    "    ('headlinesTfidf', headlines), \n",
    "    ('bodiesTfidf', bodies)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davilaYuan\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('headlinesTfidf',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  TextSelector(key='review_headline')),\n",
       "                                                                 ('countVec',\n",
       "                                                                  CountVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.int64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=1.0,\n",
       "                                                                                  max_fea...\n",
       "                                                                                   sublinear_tf=False,\n",
       "                                                                                   use_idf=True))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPipe = Pipeline([('features', features), \n",
    "                 ('clf', LogisticRegression())])\n",
    "lrPipe.fit(X=X_train, y=y_train)\n",
    "lrPipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svgPipe = Pipeline([('features', features), \n",
    "                 ('clf', SVC(gamma='auto'))])\n",
    "svgPipe.fit(X=X_train, y=y_train)\n",
    "svgPipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnbPipe = Pipeline([('features', features), \n",
    "                 ('clf', GaussianNB())])\n",
    "gnbPipe.fit(X=X_train, y=y_train)\n",
    "gnbPipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis w/ Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_true=y_dev, y_pred=pipe.predict(X=X_dev))\n",
    "real_index = [['Real']*3, list(target_dict.keys())]\n",
    "pred_colum = [['Predicted']*3, list(target_dict.keys())]\n",
    "pd.DataFrame(cf_matrix, columns=pred_colum, index=real_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify a Review as Encouraging or Decouraging Review\n",
    "+ Encourage = Positive Sentiment w/ High Helpfulness\n",
    "+ Decourage = Negative Sentiment w/ High Helpfulness\n",
    "1. New attribute with sentiments\n",
    "  + `from nltk.sentiment.vader import SentimentIntensityAnalyzer`\n",
    "  + `import flair`\n",
    "2. New attribute as combining value of sentiment and helpfulness\n",
    "    + regression? between -1 and 1, around 0: not helpful at all\n",
    "    + classification? four quadrants: helpful and sentiment\n",
    "3. Same processing steps as before on strings\n",
    "4. Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44363, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \\\n",
    "\"\"\"\n",
    "SELECT \n",
    "    helpful_votes, total_votes,\n",
    "    review_headline, review_body\n",
    "FROM \n",
    "    food_reviews\n",
    "WHERE \n",
    "    energy_100g IS NOT NULL\n",
    "    AND energy_100g < 3000\n",
    "    AND review_date >= '2010-01-01'\n",
    "    AND verified_purchase LIKE 'Y'\n",
    "    AND total_votes > 0\n",
    "\"\"\"\n",
    "# helpfulness = helpful votes / total votes\n",
    "df = pd.read_sql(sql, con=engine)\\\n",
    "    .assign(helpful=lambda df: df.helpful_votes/df.total_votes > .5)\\\n",
    "    .drop(['helpful_votes', 'total_votes'], axis=1)\n",
    "#     .assign(helpfulness=lambda df: df.helpful_votes/df.total_votes)\\\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prcoessing with individual functions \n",
    "def remove_nonword(string):\n",
    "    # remove line breaker, non-word, except space and period,\n",
    "    return re.sub(r'<br />|[^A-Za-z. ]', '', string.lower())\n",
    "def remove_space(string):\n",
    "    # remove space at setence end\n",
    "    return re.sub(r'\\s$', '', string)\n",
    "def reduce_spaces(string):\n",
    "    # reduce multiple space to single\n",
    "    return re.sub(' +', ' ', string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>five stars</td>\n",
       "      <td>it works well for nagging sensations in the st...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its not all natural and also surprise it got c...</td>\n",
       "      <td>look at the ingredients dear future customers....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>five stars</td>\n",
       "      <td>if you want angostura this is the real thing. ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best old fashion drinks..</td>\n",
       "      <td>great for making a cocktail name old fashion.....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>five stars</td>\n",
       "      <td>excellent product and very fast shipping</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     review_headline  \\\n",
       "0                                         five stars   \n",
       "1  its not all natural and also surprise it got c...   \n",
       "2                                         five stars   \n",
       "3                          best old fashion drinks..   \n",
       "4                                         five stars   \n",
       "\n",
       "                                         review_body  helpful  \n",
       "0  it works well for nagging sensations in the st...     True  \n",
       "1  look at the ingredients dear future customers....    False  \n",
       "2  if you want angostura this is the real thing. ...    False  \n",
       "3  great for making a cocktail name old fashion.....    False  \n",
       "4           excellent product and very fast shipping    False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the processing functions\n",
    "funcs = [remove_nonword, remove_space, reduce_spaces]\n",
    "for func in funcs:\n",
    "    df.review_headline = df.review_headline.apply(func)\n",
    "    df.review_body = df.review_body.apply(func)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\davilaYuan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at the ingredients dear future customers. Its not all natural and also surprise it got Caramel Color just like Coca Cola. This color is toxic and have big part in giving cancer. Look it up.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.141, 'neu': 0.651, 'pos': 0.208, 'compound': 0.2709}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.review_body[1])\n",
    "sid.polarity_scores(df.review_body[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't give vegemite any less than 5 stars, it being an Australian icon. I ordered this because I had to see what the fuss was about, has to be good- right? Ummmm....no. Lol I even had my dad try it. He said it tastes like salted s...<br />Sadly, I had to agree. We love Australia...but guys? You can keep your vegemite ;)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'compound': 0.9447}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df.review_body[69]\n",
    "print(tmp)\n",
    "sid.polarity_scores(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't give vegemite less 5 stars, Australian icon. I ordered I see fuss about, good- right? Ummmm....no. Lol I even dad try it. He said tastes like salted s...<br />Sadly, I agree. We love Australia...but guys? You keep vegemite ;)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.628, 'pos': 0.372, 'compound': 0.9447}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = ' '.join([w for w in df.review_body[69].split(' ') if w not in stopWords])\n",
    "print(tmp)\n",
    "sid.polarity_scores(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_headline                                     overseas bitters\n",
       "review_body        having found it impossible to purchase bitters...\n",
       "helpful                                                         True\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import flair\n",
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s = flair.data.Sentence(sentence)\n",
    "flair_sentiment.predict(s)\n",
    "total_sentiment = s.labels\n",
    "total_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sklearn)",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
