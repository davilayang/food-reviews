{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Explore and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# stop words list\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# disable SettingWithCopyWarning \n",
    "pd.options.mode.chained_assignment = None # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Food Facts dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949695, 175)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set dtype of code to keep values starting with 0\n",
    "# set dtype of others to avoid DtypeWarning\n",
    "data_path = 'D:\\DATA\\practice-dataset\\zipped'\n",
    "off = pd.read_csv(os.path.join(data_path, 'en.openfoodfacts.org.products.csv.zip'), \\\n",
    "                  dtype={'code': 'object', \n",
    "                         'emb_codes': 'object', 'emb_codes_tags': 'object',\n",
    "                         'first_packaging_code_geo': 'object',\n",
    "                         'cities_tags': 'object', 'additives': 'object',\n",
    "                         'ingredients_from_palm_oil_tags': 'object'}, \\\n",
    "                  compression='zip', sep='\\t')\n",
    "# data_path = '/kaggle/input/'\n",
    "# off = pd.read_csv(os.path.join(data_path, 'en.openfoodfacts.org.products.csv'), \\\n",
    "#                   dtype={'code': 'object', \n",
    "#                          'emb_codes': 'object', 'emb_codes_tags': 'object',\n",
    "#                          'first_packaging_code_geo': 'object',\n",
    "#                          'cities_tags': 'object', 'additives': 'object',\n",
    "#                          'ingredients_from_palm_oil_tags': 'object'}, \\\n",
    "#                   sep='\\t')\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not needed for cross-analysis with reviews\n",
    "dropped_cols = ['creator', 'created_t', 'created_datetime', \\\n",
    "                 'last_modified_t', 'last_modified_datetime', \\\n",
    "                 'generic_name', 'packaging', 'packaging_tags', \\\n",
    "                 'origins', 'origins_tags', \\\n",
    "                 'manufacturing_places', 'manufacturing_places_tags', \\\n",
    "                 'labels', 'emb_codes', 'emb_codes_tags', \\\n",
    "                 'first_packaging_code_geo', 'cities', 'cities_tags', \\\n",
    "                 'purchase_places', 'stores', 'countries', \\\n",
    "                 'ingredients_text', 'traces']\n",
    "# 'categories',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949695, 145)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns not used for product review\n",
    "off.drop(dropped_cols, axis=1, inplace=True)\n",
    "# filter out url columns (columns names containing 'url')\n",
    "off = off.filter(regex=r'^((?!url).)*$', axis=1)\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872540, 145)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the rows without Product Name\n",
    "off = off[off.product_name.notna()].reset_index(drop=True)\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Food Facts subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take product of \"Jif\" for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69980                       Jif Crema de Cacahuate Cremosa\n",
       "69988               Jif Creme De Amdoim C / Chocolate 450G\n",
       "69989             Jif Natural Crunchy Peanut Butter Spread\n",
       "69994    Jif Cookies N Cream and Hazelnut Pate Ã  Tartinner\n",
       "69997                             Jif Peanut Butter Creamy\n",
       "Name: product_name, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# product of Jif\n",
    "jif = off[off.product_name.str.match(r'^(JIF|Jif|jif)\\s.*')]\n",
    "jif.product_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 144)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jif.drop('categories', axis=1, inplace=True)\n",
    "# jif.product_name = jif.product_name.str.lower() # lowercase when extracting tokens\n",
    "jif.reset_index(drop=True, inplace=True)\n",
    "jif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take product of \"Cheetos\" for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 144)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product of Cheetos\n",
    "cheetos = off[off.product_name.str.match(r'^(Cheetos|CHEETOS|cheetos)\\s.*')]\n",
    "cheetos.drop('categories', axis=1, inplace=True)\n",
    "\n",
    "# cheetos.product_name = cheetos.product_name.str.lower() \n",
    "cheetos.reset_index(drop=True, inplace=True)\n",
    "cheetos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Reviews: Grocery dataset\n",
    "+ https://registry.opendata.aws/amazon-reviews/\n",
    "+ https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
    "+ http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2393378, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'D:\\DATA\\practice-dataset\\gzipped'\n",
    "amz = pd.read_csv(os.path.join(data_path, 'amazon_reviews_us_Grocery_v1_00.tsv.gz'), \\\n",
    "                  dtype={'customer_id': 'object', 'product_parent': 'object', \\\n",
    "                         'star_rating': 'object', \n",
    "                         'helpful_votes': pd.Int64Dtype(), 'total_votes': pd.Int64Dtype()}, \\\n",
    "                  compression='gzip', sep='\\t', \\\n",
    "                  error_bad_lines=False, warn_bad_lines=False)\n",
    "# data_path = '/kaggle/input/amazon_reviews_us_grocery_v1_00.tsv'\n",
    "# amz = pd.read_csv(os.path.join(data_path, 'amazon_reviews_us_Grocery_v1_00.tsv'), \\\n",
    "#                   dtype={'customer_id': 'object', 'product_parent': 'object', \\\n",
    "#                          'star_rating': 'object', \n",
    "#                          'helpful_votes': 'object', 'total_votes': 'object'}, \\\n",
    "#                   sep='\\t', \\\n",
    "#                   error_bad_lines=False, warn_bad_lines=False)\n",
    "\n",
    "# pd.Int64Dtype() allows NaN\n",
    "amz.drop(['marketplace', 'product_category', 'product_id'], axis=1, inplace=True)\n",
    "# row 1841896 contains date as star_rating\n",
    "amz.drop(1841896, axis=0, inplace=True)\n",
    "amz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Review subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take product of \"jif\" for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1413, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jif product reviews\n",
    "jif_rev = amz[amz.product_title.str.match(r'^(JIF|Jif|jif)\\s.*')]\n",
    "# jif_rev.product_title = jif_rev.product_title.str.lower()\n",
    "jif_rev.reset_index(drop=True, inplace=True)\n",
    "jif_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jif Chocolate Nut Butter Almond Granola Bars, 5 Count Pack',\n",
       "       'Jif Creamy Peanut Butter Granola Bar, 5 Ct',\n",
       "       'Jif Creamy Peanut Butter Twin Pack, 80 Ounce',\n",
       "       'Jif Whips Whipped Peanut Butter & Salty Caramel',\n",
       "       'Jif Cashew Butter, Creamy, 12 Ounce',\n",
       "       'Jif To Go Dippers with Pretzels, 3 Count',\n",
       "       'Jif Peanut Powder, 6.5 Ounce', 'Jif Creamy Peanut Butter',\n",
       "       'Jif Cashew Butter, Crunchy, 12 Ounce', 'Jif Peanut Butter'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jif_rev.product_title.unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take product of \"cheetos\" for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheetos\n",
    "che_rev = amz[amz.product_title.str.match(r'^(Cheetos|cheetos|CHEETOS)\\s.*')]\n",
    "# che_rev.product_title = che_rev.product_title.str.lower()\n",
    "che_rev.reset_index(drop=True, inplace=True)\n",
    "che_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cheetos Crunchy - 50/1 oz. bags',\n",
       "       'Cheetos Flavored Snacks, Crunchy Cheese, 1.13 Ounce (Pack of 12)',\n",
       "       'Cheetos Crunchy Cheddar Jalapeno Cheese Flavored Snacks',\n",
       "       'Cheetos Crunchy Cheese Flavored Snacks',\n",
       "       \"Cheetos Flamin' Hot and Doritos Dinamita Chile Limon 8.0 Oz [3 Pk]\",\n",
       "       \"Cheetos Flamin' Hot - 50/1 oz\",\n",
       "       'Cheetos Sweetos Cinnamon Sugar Puffs Flavored Snacks, 7 oz (Set of 2)',\n",
       "       \"Cheetos Cheese Flavored Snacks, Crunchy Flamin' Hot, 2.38 Ounce (Pack of 12)\",\n",
       "       'Cheetos Cheese Flavored Snacks, Jumbo Puffs, 9.5 Ounce (Pack of 4)',\n",
       "       'Cheetos Natural White Cheddar Puffs Cheese Flavored Snacks, 8oz Bags (Pack of 12)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "che_rev.product_title.unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mapping from `product_parent` code\n",
    "+ key: product_parent\n",
    "+ value: product title/name\n",
    "+ how?\n",
    "  + group by product_parent and product_title, count the occurance of another column\n",
    "    + getting multi-index with product_parent and product_title, with only columnt of count\n",
    "  + `reset_index` on the multi-index dataframe, get regular data frame\n",
    "  + method1:\n",
    "    + sort by count values, from large to small; drop duplicates on product_parent\n",
    "    + get the unique product_parent code for each product_title\n",
    "  + method2:\n",
    "    + get index by \n",
    "      + group by prodcut_parent and transform each row to the group's max value\n",
    "      + compare with group max value, the boolean array is the index\n",
    "    + get the unique pair by boolean slicing on array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275498, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by product_parent and product_title, get count of each title under a code\n",
    "# there could be multiple titles under the same code\n",
    "tmp = amz.loc[:, ['product_title', 'product_parent', 'customer_id']]\\\n",
    "        .groupby(['product_parent', 'product_title']).count().reset_index()\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000634</td>\n",
       "      <td>Wild Caught Icelandic Cod, Frozen Cello Pak5 l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100007845</td>\n",
       "      <td>Pamelas Cookie Fgg&amp;Jmms Bluebry&amp;Fig Ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100011767</td>\n",
       "      <td>Hidden Valley Fat Free Ranch Portion Pack Dres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100013042</td>\n",
       "      <td>Prize Winning La Tourangelle Artisinal Gourmet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100016462</td>\n",
       "      <td>Sharwood's Plain Large Puppodums (8 per pack -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_parent                                      product_title\n",
       "0      100000634  Wild Caught Icelandic Cod, Frozen Cello Pak5 l...\n",
       "1      100007845             Pamelas Cookie Fgg&Jmms Bluebry&Fig Ko\n",
       "2      100011767  Hidden Valley Fat Free Ranch Portion Pack Dres...\n",
       "3      100013042  Prize Winning La Tourangelle Artisinal Gourmet...\n",
       "4      100016462  Sharwood's Plain Large Puppodums (8 per pack -..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1\n",
    "mapping = tmp.sort_values('customer_id', ascending=False).drop_duplicates('product_parent')\n",
    "# mapping.shape\n",
    "mapping = mapping.sort_values('product_parent').drop('customer_id', axis=1).reset_index(drop=True)\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# method 2, there're still some duplicated product_parent\n",
    "idx = tmp.groupby('product_parent')['customer_id'].transform(max) == tmp['customer_id']\n",
    "mapping = tmp[idx]\n",
    "mapping.shape\n",
    "# mapping2.product_parent.values.shape, len(set(mapping2.product_parent.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the mapping\n",
    "data_path = 'D:\\DATA\\OurFoods'\n",
    "mapping.to_csv(os.path.join(data_path, 'mapping.csv'), \n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Product Name/Title\n",
    "+ Regex for processing names/titles\n",
    "  + lowercasing\n",
    "  + remove non-word but not white space, b.c, special symbols when naming\n",
    "  + remove digit and values after it, b.c. values after digits are packaging size\n",
    "  + remove space, i.e. empty string, in list\n",
    "  + remove stopwords, e.g. 'by', 'the'...etc\n",
    "+ **Problem with Regex**\n",
    "  + many product names/titles starting with digit\n",
    "    + causing too many empty tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 144), (1413, 12), (78, 144), (496, 12))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jif.shape, jif_rev.shape, cheetos.shape, che_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pname_tokenize(string):\n",
    "    \"\"\"\n",
    "    Given product name/title string, processes and outputs tuple of tokens\n",
    "    \"\"\"\n",
    "    # lower and remove non-word except spaces\n",
    "    r = re.sub(r'[^\\w\\s]', '', string.lower())\n",
    "    # remove digits and any string after it\n",
    "    r = re.sub(r'\\d.*$', '', r)\n",
    "    # remove empty string and stopwords, then return tuple\n",
    "    return tuple(sorted(set(filter(None, r.split(' '))) - set(stopWords)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jif.product_name.apply(lambda s: tuple(filter(None, re.sub(r'[^\\w\\s]|(\\d.*$)', '', s).split(' '))))\n",
    "jif_rev.product_title.apply(lambda s: tuple(filter(None, re.sub(r'[^\\w\\s]|(\\d.*$)', '', s).split(' '))))\n",
    "jif.shape, jif_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 145), (1413, 13))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jif['tokens'] = jif.product_name.apply(pname_tokenize)\n",
    "jif_rev['tokens'] = jif_rev.product_title.apply(pname_tokenize)\n",
    "jif.shape, jif_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78, 145), (496, 13))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheetos['tokens'] = cheetos.product_name.apply(pname_tokenize)\n",
    "che_rev['tokens'] = che_rev.product_title.apply(pname_tokenize)\n",
    "cheetos.shape, che_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000634</td>\n",
       "      <td>Wild Caught Icelandic Cod, Frozen Cello Pak5 l...</td>\n",
       "      <td>(caught, cello, cod, frozen, icelandic, pak, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100007845</td>\n",
       "      <td>Pamelas Cookie Fgg&amp;Jmms Bluebry&amp;Fig Ko</td>\n",
       "      <td>(bluebryfig, cookie, fggjmms, ko, pamelas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100011767</td>\n",
       "      <td>Hidden Valley Fat Free Ranch Portion Pack Dres...</td>\n",
       "      <td>(dressing, fat, free, hidden, pack, portion, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100013042</td>\n",
       "      <td>Prize Winning La Tourangelle Artisinal Gourmet...</td>\n",
       "      <td>(artisinal, gourmet, la, oil, prize, tourangel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100016462</td>\n",
       "      <td>Sharwood's Plain Large Puppodums (8 per pack -...</td>\n",
       "      <td>(large, plain, puppodums, sharwoods)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_parent                                      product_title  \\\n",
       "0      100000634  Wild Caught Icelandic Cod, Frozen Cello Pak5 l...   \n",
       "1      100007845             Pamelas Cookie Fgg&Jmms Bluebry&Fig Ko   \n",
       "2      100011767  Hidden Valley Fat Free Ranch Portion Pack Dres...   \n",
       "3      100013042  Prize Winning La Tourangelle Artisinal Gourmet...   \n",
       "4      100016462  Sharwood's Plain Large Puppodums (8 per pack -...   \n",
       "\n",
       "                                              tokens  \n",
       "0  (caught, cello, cod, frozen, icelandic, pak, w...  \n",
       "1         (bluebryfig, cookie, fggjmms, ko, pamelas)  \n",
       "2  (dressing, fat, free, hidden, pack, portion, r...  \n",
       "3  (artisinal, gourmet, la, oil, prize, tourangel...  \n",
       "4               (large, plain, puppodums, sharwoods)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping['tokens'] = mapping.product_title.apply(pname_tokenize)\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Merge\n",
    "+ AMZ dataset\n",
    "  + merge with mapping on unique id, to add tokens to amz\n",
    "+ OFF dataset\n",
    "  + tokenize the product name\n",
    "    + but product name may be duplicated, with same token\n",
    "    + group by the token, extract only the rows of product name with max counts\n",
    "  + use mapping to find unique id for the token\n",
    "+ Merge\n",
    "  + merge both on unique id (product parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((872540, 145), (2393378, 12), (267725, 3))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off.shape, amz.shape, mapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare `amz`\n",
    "+ using mapping dataset\n",
    "+ merget `amz` with mapping to get `tokens` attribute\n",
    "+ some `tokens` are empty, drop by empty tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2393378, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge amz with mapping\n",
    "amz = amz.merge(mapping[['product_parent', 'tokens']], how='left', on='product_parent')\n",
    "amz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2344543, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop empty tuples, for now\n",
    "amz = amz[amz.tokens != tuple()]\n",
    "amz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'review_id', 'product_parent', 'product_title',\n",
       "       'star_rating', 'helpful_votes', 'total_votes', 'vine',\n",
       "       'verified_purchase', 'review_headline', 'review_body', 'review_date',\n",
       "       'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare `off`\n",
    "+ problems:\n",
    "  + same product, having different pacakge size, is on different row\n",
    "  + i.e. same tokens, but having multiple entries\n",
    "+ either select one of the entries, or taking avearage on all entries\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872540, 145)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857276, 146)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process off titles\n",
    "off['tokens'] = off.product_name.apply(pname_tokenize)\n",
    "# drop empty tuple(), for now\n",
    "off = off[off.tokens != tuple()].reset_index(drop=True)\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610936, 117)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b.c. off has multiple rows with same Product Name\n",
    "# group on the product name, then taking mean on other values\n",
    "off = off.groupby('product_name', as_index=False).mean()\n",
    "off.shape # shape changes b.c. na values and strings\n",
    "# problem: only keep numeric values, other non-numeric are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>allergens_en</th>\n",
       "      <th>serving_quantity</th>\n",
       "      <th>no_nutriments</th>\n",
       "      <th>additives_n</th>\n",
       "      <th>ingredients_from_palm_oil_n</th>\n",
       "      <th>ingredients_from_palm_oil</th>\n",
       "      <th>ingredients_that_may_be_from_palm_oil_n</th>\n",
       "      <th>ingredients_that_may_be_from_palm_oil</th>\n",
       "      <th>nova_group</th>\n",
       "      <th>...</th>\n",
       "      <th>carbon-footprint-from-meat-or-fish_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "      <th>water-hardness_100g</th>\n",
       "      <th>choline_100g</th>\n",
       "      <th>phylloquinone_100g</th>\n",
       "      <th>beta-glucan_100g</th>\n",
       "      <th>inositol_100g</th>\n",
       "      <th>carnitine_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cubanisto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PrÃ©sident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- DESCATALOGADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18 marrons glacÃ©s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_name  allergens_en  serving_quantity  no_nutriments  \\\n",
       "0                               NaN               NaN            NaN   \n",
       "1           Cubanisto           NaN               NaN            NaN   \n",
       "2           PrÃ©sident           NaN               NaN            NaN   \n",
       "3     - DESCATALOGADO           NaN               NaN            NaN   \n",
       "4   18 marrons glacÃ©s           NaN               NaN            NaN   \n",
       "\n",
       "   additives_n  ingredients_from_palm_oil_n  ingredients_from_palm_oil  \\\n",
       "0          NaN                          NaN                        NaN   \n",
       "1          NaN                          NaN                        NaN   \n",
       "2          NaN                          NaN                        NaN   \n",
       "3          NaN                          NaN                        NaN   \n",
       "4          1.0                          0.0                        NaN   \n",
       "\n",
       "   ingredients_that_may_be_from_palm_oil_n  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      0.0   \n",
       "\n",
       "   ingredients_that_may_be_from_palm_oil  nova_group  ...  \\\n",
       "0                                    NaN         NaN  ...   \n",
       "1                                    NaN         NaN  ...   \n",
       "2                                    NaN         NaN  ...   \n",
       "3                                    NaN         NaN  ...   \n",
       "4                                    NaN         4.0  ...   \n",
       "\n",
       "   carbon-footprint-from-meat-or-fish_100g  nutrition-score-fr_100g  \\\n",
       "0                                      NaN                      NaN   \n",
       "1                                      NaN                      NaN   \n",
       "2                                      NaN                      NaN   \n",
       "3                                      NaN                      NaN   \n",
       "4                                      NaN                      9.0   \n",
       "\n",
       "   nutrition-score-uk_100g  glycemic-index_100g  water-hardness_100g  \\\n",
       "0                      NaN                  NaN                  NaN   \n",
       "1                      NaN                  NaN                  NaN   \n",
       "2                      NaN                  NaN                  NaN   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4                      9.0                  NaN                  NaN   \n",
       "\n",
       "   choline_100g  phylloquinone_100g  beta-glucan_100g  inositol_100g  \\\n",
       "0           NaN                 NaN               NaN            NaN   \n",
       "1           NaN                 NaN               NaN            NaN   \n",
       "2           NaN                 NaN               NaN            NaN   \n",
       "3           NaN                 NaN               NaN            NaN   \n",
       "4           NaN                 NaN               NaN            NaN   \n",
       "\n",
       "   carnitine_100g  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509281, 118)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the rows without nutrients data\n",
    "off = off[off.energy_100g.notna()]\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chocolat, noir)                                 218\n",
       "(nu,)                                            106\n",
       "(bulk, deal)                                      96\n",
       "(bte,)                                            90\n",
       "(blanc, fromage)                                  87\n",
       "                                                ... \n",
       "(suesilete,)                                       1\n",
       "(bio, extra, pÃ¢te, souple, sucre, Ã )               1\n",
       "(bean, five, salad)                                1\n",
       "(aceita, atÃºn, claro, de, en, girasol)             1\n",
       "(bars, butter, free, gluten, granola, peanut)      1\n",
       "Name: tokens, Length: 440695, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens are duplicated, i.e. same item have multiple entry\n",
    "# e.g. different packages but same item\n",
    "off.tokens.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440695, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using as slicing dataframe\n",
    "# as a dataframe \n",
    "tmp = off[['tokens', 'product_name', 'energy_100g']]\\\n",
    "        .groupby(['tokens', 'product_name'], as_index=False)\\\n",
    "        .agg({'energy_100g': 'count'})\\\n",
    "        .sort_values('energy_100g', ascending=False)\\\n",
    "        .drop_duplicates('tokens')\\\n",
    "        .reset_index(drop=True)\n",
    "tmp.columns = ['tokens', 'product_name', 'filter']\n",
    "# as dataframe for mapping between one token but multiple product_name\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440695, 119)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge off and tmp on product_name\n",
    "# i.e. getting attribute of token, that is unique\n",
    "off = off.merge(tmp.drop('filter', axis=1), how='inner', on='product_name')\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-54af980c832a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# add mapping unique id to off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'product_parent'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# drop the rows wihtout product_parent code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   7321\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7322\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7323\u001b[1;33m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7324\u001b[0m         )\n\u001b[0;32m   7325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    987\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\sklearn\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1773\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1774\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1775\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokens'"
     ]
    }
   ],
   "source": [
    "# add mapping unique id to off\n",
    "mapping.sort_values('tokens', inplace=True)\n",
    "\n",
    "off = off.merge(mapping[['product_parent', 'tokens']], how='left', on='tokens')\n",
    "# drop the rows wihtout product_parent code\n",
    "off = off[off.product_parent.notna()]\n",
    "off.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "off.product_name.str.match(r'Cheetos')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tmp = off[off.product_name.str.match(r'Cheetos')].loc[:, ['product_name', 'energy_100g']]\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Output both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147304, 134)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = amz.merge(off, how='inner', on='product_parent')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'review_id', 'product_parent', 'product_title',\n",
       "       'star_rating', 'helpful_votes', 'total_votes', 'vine',\n",
       "       'verified_purchase', 'review_headline',\n",
       "       ...\n",
       "       'water-hardness_100g', 'choline_100g', 'phylloquinone_100g',\n",
       "       'beta-glucan_100g', 'inositol_100g', 'carnitine_100g', 'tokens_x',\n",
       "       'tokens_y', 'filter', 'tokens_y'],\n",
       "      dtype='object', length=134)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows without nutrients"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_path = 'D:\\DATA\\OurFoods'\n",
    "df.to_csv(os.path.join(data_path, 'merged_amz-off_1.csv.gz'),\\\n",
    "          compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sklearn)",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
